{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf437c69-7b15-4389-9695-d848bf390978",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Title: \"Neural Barrier Certificates for Monotone Systems\"\n",
    "Code for: Learing a mixed-monotone neural barrier certificate for a traffic networks model.\n",
    "Author: Amirreza Alavi\n",
    "Contact: seyedamirreza.alavi@colorado.edu\n",
    "Affiliation: University of Colorado Boulder\n",
    "Date: 03/2025\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d841e05-b360-4e22-a615-b73052936ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "from scipy import stats\n",
    "from functools import partial\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Add\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "from math import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a696ae-2fa8-4d8c-bb31-dea6ac19b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_cr(q):\n",
    "    \n",
    "    return 10.0 * (1 - np.exp(-0.138 * q)) \n",
    "\n",
    "def sigma_cr(q):\n",
    "\n",
    "    return 10.0 * (1 - (q / 50.0)**4) * (q < 50.0)\n",
    "\n",
    "\n",
    "def phi(q):\n",
    "    \n",
    "    return 15.0 * (1 - np.exp(-0.038 * q))\n",
    "\n",
    "def sigma(q):\n",
    "\n",
    "    return 15.0 * (1 - (q / 100.0)**4) * (q < 100.0)\n",
    "\n",
    "def phi_wrap(x):\n",
    "    return np.array(phi(x), dtype=np.float64)\n",
    "\n",
    "def sigma_wrap(x):\n",
    "    return np.array(sigma(x), dtype=np.float64)\n",
    "\n",
    "def phi_cr_wrap(x):\n",
    "    return np.array(phi_cr(x), dtype=np.float64)\n",
    "\n",
    "def sigma_cr_wrap(x):\n",
    "    return np.array(sigma_cr(x), dtype=np.float64)\n",
    "\n",
    "def split_hypercubenewmethod(lower, upper, split):\n",
    "\n",
    "    lower = np.asarray(lower, dtype=np.float64)\n",
    "    upper = np.asarray(upper, dtype=np.float64)\n",
    "    split = np.asarray(split, dtype=np.float64)\n",
    "    D = lower.shape[0]\n",
    "\n",
    "    qund_list = []\n",
    "    qbar_list = []\n",
    "    \n",
    "    \n",
    "    for i in reversed(range(D)):\n",
    "        new_lower = lower.copy()\n",
    "        new_lower[i] = split[i]\n",
    "        qund_list.append(new_lower)\n",
    "        qbar_list.append(upper.copy())\n",
    "        \n",
    "    \n",
    "    qund_list.append(lower.copy())\n",
    "    qbar_list.append(split.copy())\n",
    "    \n",
    "    return np.array(qund_list, dtype=np.float64), np.array(qbar_list, dtype=np.float64)\n",
    "\n",
    "def generate_q0(N):\n",
    "    if N < 2:\n",
    "        raise ValueError(\"N must be at least 2 to accommodate the fixed values.\")\n",
    "    \n",
    "    q0bar = np.full((1, N), 5)\n",
    "    \n",
    "    q0bar[0, 1] = 18\n",
    "    \n",
    "    q0und = np.zeros((1, N), dtype=int)\n",
    "    \n",
    "    return q0bar, q0und\n",
    "\n",
    "def generate_qu(N):\n",
    "    if N < 2:\n",
    "        raise ValueError(\"N must be at least 2 to accommodate the fixed second element.\")\n",
    "    \n",
    "    qubar = np.full((1, N), 50)\n",
    "    \n",
    "    quund = np.zeros((1, N), dtype=int)\n",
    "    \n",
    "    quund[0, 1] = 30\n",
    "    \n",
    "    return qubar, quund\n",
    "\n",
    "def generate_bounds(N):\n",
    "    if N < 2:\n",
    "        raise ValueError(\"N must be at least 2 to accommodate the fixed first two elements.\")\n",
    "\n",
    "    lower = [0] * N\n",
    "\n",
    "    upper = [50] * N\n",
    "    upper[1] = 30\n",
    "\n",
    "    split = [5, 18]\n",
    "    pattern = [5, 5, 5, 5]\n",
    "    remaining = N - 2  \n",
    "    \n",
    "    for i in range(remaining):\n",
    "        split.append(pattern[i % len(pattern)])\n",
    "    \n",
    "    return lower, upper, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a64837-6fb5-4256-9a59-732b53f7ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 \n",
    "\n",
    "q0bar, q0und = generate_q0(N)\n",
    "qubar, quund = generate_qu(N)\n",
    "lower, upper, split = generate_bounds(N)\n",
    "\n",
    "qund, qbar = split_hypercubenewmethod(lower, upper, split)\n",
    "\n",
    "h=0.1\n",
    "\n",
    "qbars = tf.split(qbar, num_or_size_splits=qbar.shape[1], axis=1)\n",
    "qunds = tf.split(qund, num_or_size_splits=qbar.shape[1], axis=1)\n",
    "\n",
    "\n",
    "phi_qbar = []\n",
    "sigma_qbar = []\n",
    "\n",
    "for i, q in enumerate(qbars):\n",
    "    \n",
    "    if i == 1:\n",
    "        phi_qbar.append(tf.numpy_function(phi_cr_wrap, [q], tf.float64))\n",
    "    else:\n",
    "        phi_qbar.append(tf.numpy_function(phi_wrap, [q], tf.float64))\n",
    "    \n",
    "    if i == 0:\n",
    "        sigma_qbar.append(None)\n",
    "    else:\n",
    "        if i == 1:\n",
    "            sigma_qbar.append(tf.numpy_function(sigma_cr_wrap, [q], tf.float64))\n",
    "        else:\n",
    "            sigma_qbar.append(tf.numpy_function(sigma_wrap, [q], tf.float64))\n",
    "\n",
    "phi_qund = []\n",
    "sigma_qund = []\n",
    "\n",
    "for i, q in enumerate(qunds):\n",
    "    if i == 1:\n",
    "        phi_qund.append(tf.numpy_function(phi_cr_wrap, [q], tf.float64))\n",
    "    else:\n",
    "        phi_qund.append(tf.numpy_function(phi_wrap, [q], tf.float64))\n",
    "        \n",
    "    if i == 0:\n",
    "        sigma_qund.append(None)\n",
    "    else:\n",
    "        if i == 1:\n",
    "            sigma_qund.append(tf.numpy_function(sigma_cr_wrap, [q], tf.float64))\n",
    "        else:\n",
    "            sigma_qund.append(tf.numpy_function(sigma_wrap, [q], tf.float64))\n",
    "\n",
    "\n",
    "\n",
    "F_qbar = []\n",
    "\n",
    "F_qbar.append(tf.constant(9.0, shape=(N+1, 1), dtype=tf.float64))\n",
    "\n",
    "for i in range(len(phi_qbar) - 1):\n",
    "    F_qbar.append(tf.minimum(phi_qbar[i], sigma_qbar[i + 1]))\n",
    "\n",
    "F_qbar.append(phi_qbar[-1])\n",
    "\n",
    "\n",
    "F_qund = []\n",
    "\n",
    "F_qund.append(tf.constant(9.0, shape=(N+1, 1), dtype=tf.float64))\n",
    "\n",
    "for i in range(len(phi_qbar) - 1):\n",
    "    F_qund.append(tf.minimum(phi_qund[i], sigma_qund[i + 1]))\n",
    "\n",
    "F_qund.append(phi_qund[-1])\n",
    "\n",
    "\n",
    "qbarsn_list = []\n",
    "for i in range(len(qbars)):\n",
    "    qbarsn = qbars[i] + h * (F_qbar[i] - F_qbar[i + 1])\n",
    "    qbarsn_list.append(qbarsn)\n",
    "\n",
    "fqbar = tf.concat(qbarsn_list, axis=1)\n",
    "\n",
    "\n",
    "qundsn_list = []\n",
    "for i in range(len(qunds)):\n",
    "    qundsn = qunds[i] + h * (F_qund[i] - F_qund[i + 1])\n",
    "    qundsn_list.append(qundsn)\n",
    "\n",
    "fqund = tf.concat(qundsn_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca0af6-2578-4767-ac2a-f3071af24712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H1\n",
    "\n",
    "modelh1 = tf.keras.Sequential()\n",
    "modelh1.add(layers.Dense(40, use_bias=True, activation = 'tanh' ,input_shape=(N,),kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "modelh1.add(layers.Dense(40, use_bias=True, activation = 'tanh' , kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "modelh1.add(layers.Dense(40, use_bias=True, activation = 'tanh' ,kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "modelh1.add(layers.Dense(40, use_bias=True, activation = 'tanh' ,kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "modelh1.add(layers.Dense(40, use_bias=True, activation = 'tanh' ,kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "modelh1.add(layers.Dense(1,use_bias=True, activation = 'linear',kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "\n",
    "# H2\n",
    "\n",
    "modelh2 = tf.keras.Sequential()\n",
    "modelh2.add(layers.Dense(40, use_bias=True, activation = 'tanh' , input_shape=(N,),kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "modelh2.add(layers.Dense(40, use_bias=True, activation = 'tanh' , kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "modelh2.add(layers.Dense(40, use_bias=True, activation = 'tanh' , kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "modelh2.add(layers.Dense(40, use_bias=True, activation = 'tanh' , kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "modelh2.add(layers.Dense(40, use_bias=True, activation = 'tanh' , kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "modelh2.add(layers.Dense(1,use_bias=True, activation = 'linear',kernel_constraint=tf.keras.constraints.NonNeg()))\n",
    "\n",
    "lr1_initial = 1e-2\n",
    "lr2_initial = 1e-2\n",
    "\n",
    "opt1 = tf.keras.optimizers.Adam(lr1_initial)\n",
    "opt2 = tf.keras.optimizers.Adam(lr2_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228add8-f621-453e-8b49-c8b5b896e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300000\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "eta= 0.001\n",
    "etaa=0.0000001\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    if i == 500:\n",
    "        new_lr1 = 1e-3 \n",
    "        new_lr2 = 1e-3 \n",
    "        opt1.learning_rate.assign(new_lr1)\n",
    "        opt2.learning_rate.assign(new_lr2)\n",
    "\n",
    "    \n",
    "    with tf.GradientTape() as tape0, tf.GradientTape() as tape1:\n",
    "        \n",
    "        \n",
    "        H1_q0bar = tf.reshape(modelh1(q0bar, training=True), [q0bar.shape[0], 1])\n",
    "        H1_q0und = tf.reshape(modelh1(q0und, training=True), [q0und.shape[0], 1])\n",
    "        H1_qubar = tf.reshape(modelh1(qubar, training=True), [qubar.shape[0], 1])\n",
    "        H1_quund = tf.reshape(modelh1(quund, training=True), [quund.shape[0], 1])\n",
    "        H1_qund = tf.reshape(modelh1(qund, training=True), [qund.shape[0], 1])\n",
    "        H1_qbar = tf.reshape(modelh1(qbar, training=True), [qbar.shape[0], 1])\n",
    "        \n",
    "        H2_q0und = tf.reshape(modelh2(q0und, training=True), [q0und.shape[0], 1])\n",
    "        H2_q0bar = tf.reshape(modelh2(q0bar, training=True), [q0bar.shape[0], 1])\n",
    "        H2_quund = tf.reshape(modelh2(quund, training=True), [quund.shape[0], 1])\n",
    "        H2_qubar = tf.reshape(modelh2(qubar, training=True), [qubar.shape[0], 1])\n",
    "        H2_qund = tf.reshape(modelh2(qund, training=True), [qund.shape[0], 1])\n",
    "        H2_qbar = tf.reshape(modelh2(qbar, training=True), [qbar.shape[0], 1])\n",
    "\n",
    "        H1fqbar = tf.reshape(modelh1(fqbar, training=True), [fqbar.shape[0], 1])\n",
    "        H2fqund = tf.reshape(modelh2(fqund, training=True), [fqund.shape[0], 1])\n",
    "\n",
    "   \n",
    "        loss_h3 = tf.reduce_sum(tf.nn.relu(tf.subtract(eta,eta)))\n",
    "        loss_h4 = tf.reduce_sum(tf.nn.relu(tf.subtract(eta,eta)))\n",
    "\n",
    "\n",
    "        loss_h3 += tf.reduce_sum(tf.nn.relu(tf.subtract(H1_q0bar-H2_q0und,-etaa))) \n",
    "        loss_h3 += tf.reduce_sum(tf.nn.relu(etaa-(H1_quund-H2_qubar)))\n",
    "        loss_h3 += tf.reduce_sum(tf.math.sign(tf.nn.relu(-(H1_qund-H2_qbar)))* tf.nn.relu(H1fqbar-H2fqund))\n",
    "\n",
    "        \n",
    "        loss_h4 += tf.reduce_max(tf.square(tf.nn.relu(H1_q0bar-H2_q0und + 30))) \n",
    "        loss_h4 += tf.reduce_max(tf.square(tf.nn.relu(eta-H1_quund+H2_qubar)))\n",
    "        loss_h4 += tf.reduce_max(tf.math.sign(tf.nn.relu(-(H1_qund-H2_qbar)))* tf.square(tf.nn.relu(H1fqbar-H2fqund)))\n",
    "\n",
    "\n",
    "        if tf.reduce_sum(loss_h3) == 0 and i > 11:\n",
    "            print(f\"Training terminated at epoch {i} as loss reached exactly zero.\")\n",
    "            break\n",
    "        \n",
    "        grad_h1 = tape0.gradient(loss_h4, modelh1.trainable_variables)\n",
    "        grad_h2 = tape1.gradient(loss_h4, modelh2.trainable_variables)\n",
    "        \n",
    "        \n",
    "        if (i // 10) % 2 == 0:\n",
    "            clipgrad_h1 = [tf.clip_by_norm(g, 2) for g in grad_h1]\n",
    "            opt1.apply_gradients(zip(clipgrad_h1, modelh1.trainable_variables))\n",
    "        else:\n",
    "            if grad_h2 is not None:\n",
    "                clipgrad_h2 = [tf.clip_by_norm(g, 2) for g in grad_h2]\n",
    "                opt2.apply_gradients(zip(clipgrad_h2, modelh2.trainable_variables))\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Epoch {i}: loss_h3 = {loss_h3.numpy()}, loss_h4 = {loss_h4.numpy()}\")\n",
    "            \n",
    "    \n",
    "t2 = time.perf_counter()\n",
    "tot = t2 - t1\n",
    "print(f'Total runtime: {tot}s')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
